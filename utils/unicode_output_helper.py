#!/usr/bin/env python3
"""
ç»Ÿä¸€çš„Unicodeè¾“å‡ºå¤„ç†æ¨¡å—

ä¸ºæ‰€æœ‰Agentæä¾›ç»Ÿä¸€çš„Unicodeå¤„ç†åŠŸèƒ½ï¼Œç¡®ä¿ä¸­æ–‡æ­£ç¡®æ˜¾ç¤ºã€‚
"""

import sys
import os
import builtins

# ä¿å­˜åŸå§‹printå‡½æ•°ä»¥é¿å…é€’å½’
_original_print = builtins.print

# å¯¼å…¥ç°æœ‰çš„Unicodeå¤„ç†å‡½æ•°
try:
    from utils.unicode_helper import aggressive_unicode_decode, clean_debug_output, ensure_utf8_environment
except ImportError:
    def aggressive_unicode_decode(text):
        """åå¤‡çš„Unicodeè§£ç å‡½æ•°"""
        if not isinstance(text, str):
            return str(text)
        try:
            import re
            pattern = r'\\u([0-9a-fA-F]{4})'
            def replace_match(match):
                hex_code = match.group(1)
                try:
                    return chr(int(hex_code, 16))
                except (ValueError, OverflowError):
                    return match.group(0)
            
            # é‡å¤è§£ç ç›´åˆ°æ²¡æœ‰å˜åŒ–
            prev_text = ""
            max_iterations = 3
            iteration = 0
            while prev_text != text and iteration < max_iterations and '\\u' in text:
                prev_text = text
                text = re.sub(pattern, replace_match, text)
                iteration += 1
            
            return text
        except Exception:
            return str(text)
    
    def clean_debug_output(text):
        return str(text)
    
    def ensure_utf8_environment():
        os.environ['PYTHONIOENCODING'] = 'utf-8'
        if 'LC_CTYPE' not in os.environ:
            os.environ['LC_CTYPE'] = 'zh_CN.UTF-8'

def unicode_aware_print(*args, **kwargs):
    """å…¨å±€çš„Unicodeæ„ŸçŸ¥printå‡½æ•°"""
    processed_args = []
    for arg in args:
        if isinstance(arg, str) and '\\u' in arg:
            processed_arg = aggressive_unicode_decode(arg)
            processed_args.append(processed_arg)
        else:
            processed_args.append(arg)
    
    # ä½¿ç”¨åŸå§‹printå‡½æ•°é¿å…é€’å½’
    _original_print(*processed_args, **kwargs)

def setup_unicode_environment_for_agents():
    """ä¸ºæ‰€æœ‰Agentè®¾ç½®Unicodeç¯å¢ƒ"""
    # è®¾ç½®åŸºç¡€Unicodeç¯å¢ƒ
    ensure_utf8_environment()
    
    # è®¾ç½®Pythonè¾“å‡ºç¼–ç 
    if hasattr(sys.stdout, 'reconfigure'):
        sys.stdout.reconfigure(encoding='utf-8', errors='replace')
    if hasattr(sys.stderr, 'reconfigure'):
        sys.stderr.reconfigure(encoding='utf-8', errors='replace')
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ['PYTHONIOENCODING'] = 'utf-8:replace'
    os.environ['LC_CTYPE'] = 'zh_CN.UTF-8'
    
    _original_print("âœ… [Unicode] æ‰€æœ‰Agentçš„Unicodeç¯å¢ƒè®¾ç½®å®Œæˆ")

def apply_global_unicode_fixes():
    """åº”ç”¨å…¨å±€Unicodeä¿®å¤"""
    setup_unicode_environment_for_agents()
    
    # æ›¿æ¢å†…ç½®print
    builtins.print = unicode_aware_print
    
    _original_print("ğŸ”§ [Unicode] å…¨å±€Unicodeä¿®å¤å·²åº”ç”¨")

class AgentOutputCapture:
    """Agentè¾“å‡ºæ•è·å’ŒUnicodeå¤„ç†å™¨"""
    
    def __init__(self, agent_name: str):
        self.agent_name = agent_name
        self.captured_outputs = []
        
    def capture_and_decode(self, output) -> str:
        """æ•è·å¹¶è§£ç Agentè¾“å‡º"""
        if not output:
            return ""
            
        output_str = str(output)
        
        # å¦‚æœåŒ…å«Unicodeè½¬ä¹‰ï¼Œè¿›è¡Œè§£ç 
        if '\\u' in output_str:
            decoded_output = aggressive_unicode_decode(output_str)
            self.captured_outputs.append({
                'original': output_str,
                'decoded': decoded_output,
                'agent': self.agent_name
            })
            return decoded_output
        
        return output_str

def decode_agent_output(text):
    """ç®€å•çš„Agentè¾“å‡ºè§£ç å‡½æ•°"""
    if isinstance(text, str) and '\\u' in text:
        return aggressive_unicode_decode(text)
    return str(text)

def patch_json_encoder():
    """ä¿®è¡¥JSONç¼–ç å™¨ä»¥å¤„ç†Unicodeè½¬ä¹‰"""
    import json
    import builtins
    
    # ä¿å­˜åŸå§‹çš„json.dumps
    original_json_dumps = json.dumps
    
    def unicode_aware_json_dumps(obj, *args, **kwargs):
        """Unicodeæ„ŸçŸ¥çš„JSON dumps"""
        # ç¡®ä¿ensure_ascii=Falseï¼Œé¿å…ä¸­æ–‡è¢«è½¬ä¹‰
        kwargs.setdefault('ensure_ascii', False)
        result = original_json_dumps(obj, *args, **kwargs)
        
        # å¦‚æœç»“æœä»ç„¶åŒ…å«Unicodeè½¬ä¹‰ï¼Œè¿›è¡Œè§£ç 
        if isinstance(result, str) and '\\u' in result:
            try:
                result = aggressive_unicode_decode(result)
            except:
                pass  # å¦‚æœè§£ç å¤±è´¥ï¼Œè¿”å›åŸå§‹ç»“æœ
                
        return result
    
    # æ›¿æ¢å…¨å±€çš„json.dumps
    json.dumps = unicode_aware_json_dumps
    
    # ä¹Ÿè¦æ›¿æ¢å†…ç½®çš„jsonæ¨¡å—
    try:
        import sys
        if 'json' in sys.modules:
            sys.modules['json'].dumps = unicode_aware_json_dumps
    except:
        pass

def patch_agent_serialization():
    """ä¿®è¡¥Agentæ¡†æ¶çš„åºåˆ—åŒ–è¿‡ç¨‹"""
    try:
        # å°è¯•ä¿®è¡¥openai-agentsçš„åºåˆ—åŒ–
        from agents.tool import Tool
        from agents import Agent
        
        # ä¿å­˜åŸå§‹æ–¹æ³•
        if hasattr(Tool, '_original_to_dict'):
            return  # å·²ç»ä¿®è¡¥è¿‡äº†
        
        # ä¿®è¡¥Toolçš„åºåˆ—åŒ–
        if hasattr(Tool, 'to_dict'):
            Tool._original_to_dict = Tool.to_dict
            
            def unicode_aware_to_dict(self):
                result = self._original_to_dict()
                # å¤„ç†ç»“æœä¸­çš„Unicodeè½¬ä¹‰
                if isinstance(result, dict):
                    for key, value in result.items():
                        if isinstance(value, str) and '\\u' in value:
                            result[key] = aggressive_unicode_decode(value)
                        elif isinstance(value, dict):
                            for sub_key, sub_value in value.items():
                                if isinstance(sub_value, str) and '\\u' in sub_value:
                                    value[sub_key] = aggressive_unicode_decode(sub_value)
                return result
            
            Tool.to_dict = unicode_aware_to_dict
        
        # ä¿®è¡¥Agentçš„åºåˆ—åŒ–
        if hasattr(Agent, '_serialize_tools'):
            Agent._original_serialize_tools = Agent._serialize_tools
            
            def unicode_aware_serialize_tools(self):
                result = self._original_serialize_tools()
                # å¤„ç†å·¥å…·åºåˆ—åŒ–ç»“æœä¸­çš„Unicode
                if isinstance(result, list):
                    for tool_info in result:
                        if isinstance(tool_info, dict):
                            for key, value in tool_info.items():
                                if isinstance(value, str) and '\\u' in value:
                                    tool_info[key] = aggressive_unicode_decode(value)
                                elif isinstance(value, dict) and 'description' in value:
                                    if '\\u' in value['description']:
                                        value['description'] = aggressive_unicode_decode(value['description'])
                return result
            
            Agent._serialize_tools = unicode_aware_serialize_tools
            
    except ImportError:
        pass  # agentsæ¨¡å—ä¸å¯ç”¨
    except Exception as e:
        _original_print(f"âš ï¸ [Unicode] Agentåºåˆ—åŒ–ä¿®è¡¥å¤±è´¥: {e}")

def apply_comprehensive_unicode_fixes():
    """åº”ç”¨å…¨é¢çš„Unicodeä¿®å¤"""
    setup_unicode_environment_for_agents()
    
    # ä¿®è¡¥JSONç¼–ç å™¨
    patch_json_encoder()
    
    # ä¿®è¡¥Agentæ¡†æ¶åºåˆ—åŒ–
    patch_agent_serialization()
    
    # æ›¿æ¢å†…ç½®print
    import builtins
    builtins.print = unicode_aware_print
    
    _original_print("ğŸ”§ [Unicode] å…¨é¢Unicodeä¿®å¤å·²åº”ç”¨ï¼ˆåŒ…å«JSONå’ŒAgentåºåˆ—åŒ–ä¿®è¡¥ï¼‰")

if __name__ == "__main__":
    # æµ‹è¯•Unicodeå¤„ç†åŠŸèƒ½
    test_cases = [
        "\\u4f60\\u597d\\u4e16\\u754c",  # ä½ å¥½ä¸–ç•Œ
        "\\u57fa\\u91d1\\u4ee3\\u7801: 508089",  # åŸºé‡‘ä»£ç : 508089
        '{"name": "\\u534e\\u590f\\u57fa\\u91d1"}',  # {"name": "åå¤åŸºé‡‘"}
    ]
    
    _original_print("ğŸ§ª æµ‹è¯•Unicodeè¾“å‡ºå¤„ç†å™¨...")
    for i, test_case in enumerate(test_cases, 1):
        _original_print(f"æµ‹è¯• {i}: {test_case}")
        decoded = aggressive_unicode_decode(test_case)
        _original_print(f"è§£ç ç»“æœ: {decoded}")
        _original_print("-" * 50)
    
    _original_print("âœ… Unicodeè¾“å‡ºå¤„ç†å™¨æµ‹è¯•å®Œæˆ") 
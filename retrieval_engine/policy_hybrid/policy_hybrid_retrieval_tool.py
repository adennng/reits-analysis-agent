# policy_hybrid_retrieval_tool.py
"""
æ”¿ç­–æ–‡ä»¶æ··åˆæ£€ç´¢ä¸»å·¥å…·
å®ç°å®Œæ•´çš„æ”¿ç­–æ–‡ä»¶æ··åˆæ£€ç´¢æµç¨‹ï¼š
1. ç”Ÿæˆæ£€ç´¢å‚æ•° -> 2. æ··åˆæ£€ç´¢ -> 3. ç¬¬ä¸€æ¬¡æ‰©å±• -> 4. ç›¸å…³æ€§æ‰“åˆ† -> 
5. è¿‡æ»¤4åˆ†ä»¥ä¸Šè¯­å— -> 6. æŒ‰æ–‡ä»¶åˆ†ç»„ -> 7. ç¬¬äºŒæ¬¡æ‰©å±•åˆå¹¶ -> 8. ç»Ÿä¸€LLMé—®ç­”
"""
import sys
import os
import json
from typing import List, Dict, Optional
from openai import OpenAI

# è®¾ç½®æ­£ç¡®çš„Pythonè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(current_dir))))
sys.path.insert(0, project_root)

from knowledge_retrieval.config.prompts import POLICY_UNIFIED_ANSWER_GENERATION_PROMPT
from knowledge_retrieval.config.model_config import MODEL_CONFIG
from .models.policy_data_models import PolicySearchResult, PolicyScoredResult, PolicyFileGroup, PolicyRetrievalResponse
from .tools.policy_params_generator import generate_policy_search_params
from .tools.policy_search_tools import PolicyHybridSearchTool
from .tools.policy_text_processor import PolicyTextProcessor
from .tools.policy_relevance_scorer import PolicyRelevanceScorer

class PolicyHybridRetrievalTool:
    """æ”¿ç­–æ–‡ä»¶æ··åˆæ£€ç´¢ä¸»å·¥å…·"""
    
    def __init__(self):
        print("[PolicyHybridRetrievalTool] æ­£åœ¨åˆå§‹åŒ–...")
        
        # åˆå§‹åŒ–å„ä¸ªç»„ä»¶
        self.hybrid_search_tool = PolicyHybridSearchTool()
        self.text_processor = PolicyTextProcessor()
        self.relevance_scorer = PolicyRelevanceScorer()
        
        # è®¾ç½®LLMå®¢æˆ·ç«¯
        self._setup_llm()
        
        print("[PolicyHybridRetrievalTool] åˆå§‹åŒ–å®Œæˆ")
    
    def _setup_llm(self):
        """è®¾ç½®LLMå®¢æˆ·ç«¯ç”¨äºæœ€ç»ˆé—®ç­”"""
        try:
            llm_config = MODEL_CONFIG["ali"]["deepseek-v3"]
            self.llm_client = OpenAI(
                api_key=llm_config["api_key"],
                base_url=llm_config["base_url"]
            )
            self.model_name = llm_config["model"]
            print(f"[PolicyHybridRetrievalTool] LLMå®¢æˆ·ç«¯è®¾ç½®å®Œæˆ: {self.model_name}")
            
        except Exception as e:
            print(f"[PolicyHybridRetrievalTool] LLMè®¾ç½®å¤±è´¥: {e}")
            self.llm_client = None
            self.model_name = None
    
    def execute_retrieval(self, question: str) -> PolicyRetrievalResponse:
        """
        æ‰§è¡Œå®Œæ•´çš„æ”¿ç­–æ–‡ä»¶æ··åˆæ£€ç´¢æµç¨‹
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            
        Returns:
            PolicyRetrievalResponse: æ£€ç´¢å“åº”
        """
        print(f"[PolicyHybridRetrievalTool] å¼€å§‹æ‰§è¡Œæ”¿ç­–æ–‡ä»¶æ£€ç´¢: {question}")
        
        # å£°æ˜ç”¨äºè·Ÿè¸ªè¿›åº¦çš„å˜é‡
        search_results = None
        scores = None
        scored_results = None
        file_groups = None
        
        try:
            # æ­¥éª¤1: ç”Ÿæˆæ£€ç´¢å‚æ•°
            search_params = generate_policy_search_params(question)
            print(f"[PolicyHybridRetrievalTool] æ£€ç´¢å‚æ•°ç”Ÿæˆå®Œæˆ:")
            print(f"  å‘é‡é—®é¢˜: {search_params.vector_question}")
            print(f"  å…³é”®è¯: {search_params.keywords}")
            
            # æ­¥éª¤2: æ‰§è¡Œæ··åˆæ£€ç´¢
            search_results = self.hybrid_search_tool.search(
                vector_question=search_params.vector_question,
                keywords=search_params.keywords
            )
            
            # æƒ…å†µ1: æ··åˆæ£€ç´¢æ— ç»“æœ ğŸ”„ å¯é‡è¯•å¤±è´¥
            if not search_results:
                return PolicyRetrievalResponse(
                    question=question,
                    answer="æ··åˆæ£€ç´¢æœªæ‰¾åˆ°ç›¸å…³æ”¿ç­–æ–‡ä»¶",
                    reference_files=[],
                    is_found=False,
                    error="æ··åˆæ£€ç´¢æœªè¿”å›ä»»ä½•ç»“æœ",
                    failure_type="retryable",  # Agent2å¯é‡è¯•
                    debug_info={
                        "step": "hybrid_search", 
                        "search_params": {
                            "vector_question": search_params.vector_question,
                            "keywords": search_params.keywords
                        }
                    }
                )
            
            # æ­¥éª¤3: ç¬¬ä¸€æ¬¡æ‰©å±•
            expanded_texts = self.text_processor.batch_first_expansion(search_results)
            
            # æ­¥éª¤4: ç›¸å…³æ€§æ‰“åˆ†
            scores = self.relevance_scorer.batch_score_relevance(question, expanded_texts)
            
            # æ­¥éª¤5: è¿‡æ»¤4åˆ†ä»¥ä¸Šè¯­å—
            scored_results = []
            for result, score, expanded_text in zip(search_results, scores, expanded_texts):
                if score >= 4:  # ä¿ç•™4åˆ†å’Œ5åˆ†çš„è¯­å—
                    scored_result = PolicyScoredResult(
                        search_result=result,
                        relevance_score=score,
                        expanded_text_initial=expanded_text,
                        expanded_text_final="",  # ç¬¬äºŒæ¬¡æ‰©å±•åå¡«å…¥
                        from_methods=result.from_methods,
                        final_score=float(score)
                    )
                    scored_results.append(scored_result)
            
            print(f"[PolicyHybridRetrievalTool] è¿‡æ»¤åä¿ç•™{len(scored_results)}ä¸ª4åˆ†ä»¥ä¸Šè¯­å—")
            
            # æƒ…å†µ2: æ— 4åˆ†ä»¥ä¸Šè¯­å— âŒ æœ€ç»ˆå¤±è´¥
            if not scored_results:
                return PolicyRetrievalResponse(
                    question=question,
                    answer="æ ¹æ®æ£€ç´¢çš„æ”¿ç­–æ–‡ä»¶æ— æ³•æ‰¾åˆ°ç›¸å…³è§„å®š",
                    reference_files=[],
                    is_found=False,
                    error="æ²¡æœ‰æ‰¾åˆ°ç›¸å…³æ€§è¶³å¤Ÿé«˜çš„å†…å®¹",
                    failure_type="final",  # æœ€ç»ˆå¤±è´¥ï¼Œä¸å†å¤„ç†
                    debug_info={
                        "step": "relevance_scoring", 
                        "max_score": max(scores) if scores else 0,
                        "total_results": len(search_results)
                    }
                )
            
            # æ­¥éª¤6-7: æŒ‰æ–‡ä»¶åˆ†ç»„å¹¶è¿›è¡Œç¬¬äºŒæ¬¡æ‰©å±•
            file_groups = self.text_processor.group_by_file_and_second_expansion(scored_results)
            
            # æ­¥éª¤8: ç»Ÿä¸€LLMé—®ç­”
            final_response = self._unified_llm_answer(question, file_groups)
            
            return final_response
            
        except Exception as e:
            print(f"[PolicyHybridRetrievalTool] æ£€ç´¢æ‰§è¡Œå¤±è´¥: {e}")
            
            # æ™ºèƒ½å¼‚å¸¸å¤„ç†ï¼šæ ¹æ®å·²å®Œæˆçš„æ­¥éª¤åˆ¤æ–­å¤±è´¥ç±»å‹
            return self._handle_exception_by_progress(
                question, e, search_results, scores, scored_results, file_groups
            )
    
    def _unified_llm_answer(self, question: str, file_groups: List[PolicyFileGroup]) -> PolicyRetrievalResponse:
        """
        ç»Ÿä¸€LLMé—®ç­”ï¼šå°†æ‰€æœ‰æ–‡ä»¶ä¿¡æ¯ä¸€èµ·æä¾›ç»™LLM
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            file_groups: æŒ‰æ–‡ä»¶åˆ†ç»„çš„ç»“æœ
            
        Returns:
            PolicyRetrievalResponse: æœ€ç»ˆå“åº”
        """
        print(f"[PolicyHybridRetrievalTool] å¼€å§‹ç»Ÿä¸€LLMé—®ç­”ï¼Œå…±{len(file_groups)}ä¸ªæ–‡ä»¶")
        
        # æƒ…å†µ3: LLMå®¢æˆ·ç«¯ä¸å¯ç”¨ ğŸ”§ éœ€Agent2å¤„ç†
        if not self.llm_client:
            # å‡†å¤‡ç»™Agent2çš„æ£€ç´¢å†…å®¹
            all_texts = []
            all_files = []
            for group in file_groups:
                all_texts.append(f"æ–‡ä»¶ï¼š{group.document_title}\n{group.merged_text}")
                all_files.append({
                    "document_title": group.document_title,
                    "publish_date": group.publish_date,
                    "issuing_agency": group.issuing_agency,
                    "website": group.website
                })
            
            retrieval_content = "\n\n".join(all_texts)
            
            # ğŸ”§ ä¸ºAgent2æˆªæ–­æ£€ç´¢å†…å®¹ï¼Œé¿å…ä¼ é€’è¿‡é•¿å†…å®¹
            if len(retrieval_content) > 40000:
                print(f"[PolicyHybridRetrievalTool] ä¼ é€’ç»™Agent2çš„å†…å®¹è¿‡é•¿({len(retrieval_content)}å­—ç¬¦)ï¼Œæˆªæ–­è‡³40000å­—ç¬¦")
                retrieval_content = retrieval_content[:40000] + "\n\n[å†…å®¹å› é•¿åº¦é™åˆ¶è¢«æˆªæ–­...]"
            
            return PolicyRetrievalResponse(
                question=question,
                answer="æ£€ç´¢åˆ°ç›¸å…³å†…å®¹ä½†LLMå¤„ç†å¤±è´¥",
                reference_files=all_files,
                is_found=False,
                error="LLMå¤„ç†å¤±è´¥",
                failure_type="needs_agent2",  # éœ€è¦Agent2å¤„ç†
                retrieval_content=retrieval_content,  # å…³é”®ï¼šè¿”å›æˆªæ–­åçš„æ£€ç´¢å†…å®¹
                debug_info={"step": "llm_unavailable", "files_count": len(file_groups)}
            )
        
        try:
            # æ„å»ºæ–‡ä»¶å†…å®¹å­—ç¬¦ä¸²
            file_contents_parts = []
            file_info_map = {}  # æ–‡ä»¶ååˆ°è¯¦ç»†ä¿¡æ¯çš„æ˜ å°„
            
            print(f"[PolicyHybridRetrievalTool] æ„å»ºLLMè¾“å…¥å†…å®¹ï¼Œæ–‡ä»¶å·²æŒ‰å‘å¸ƒæ—¥æœŸæ’åºï¼ˆæœ€æ–°åœ¨å‰ï¼‰")
            
            for group in file_groups:
                file_content = f"""
æ–‡ä»¶åï¼š{group.document_title}
å‘å¸ƒæ—¥æœŸï¼š{group.publish_date}
å‘å¸ƒæœºæ„ï¼š{group.issuing_agency}
ç½‘ç«™æ¥æºï¼š{group.website}

æ–‡ä»¶å†…å®¹ï¼š
{group.merged_text}
"""
                file_contents_parts.append(file_content)
                
                # ä¿å­˜æ–‡ä»¶ä¿¡æ¯æ˜ å°„
                file_info_map[group.document_title] = {
                    "document_title": group.document_title,
                    "publish_date": group.publish_date,
                    "issuing_agency": group.issuing_agency,
                    "website": group.website
                }
            
            file_contents_str = "\n" + "="*50 + "\n".join(file_contents_parts)
            
            # ğŸ”§ æ·»åŠ 40000å­—ç¬¦æˆªæ–­é€»è¾‘ï¼Œé¿å…LLMè¾“å…¥è¿‡é•¿
            if len(file_contents_str) > 40000:
                print(f"[PolicyHybridRetrievalTool] æ–‡ä»¶å†…å®¹è¿‡é•¿({len(file_contents_str)}å­—ç¬¦)ï¼Œæˆªæ–­è‡³40000å­—ç¬¦")
                file_contents_str_for_llm = file_contents_str[:40000] + "\n\n[å†…å®¹å› é•¿åº¦é™åˆ¶è¢«æˆªæ–­...]"
            else:
                file_contents_str_for_llm = file_contents_str
            
            # æ„å»ºæç¤ºè¯
            prompt = POLICY_UNIFIED_ANSWER_GENERATION_PROMPT.format(
                question=question,
                file_contents=file_contents_str_for_llm
            )
            
            # è°ƒç”¨LLM
            response = self.llm_client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "user", "content": prompt}
                ],
                temperature=0.0
            )
            
            llm_output = response.choices[0].message.content.strip()
            print(f"[PolicyHybridRetrievalTool] LLMåŸå§‹è¾“å‡º: {llm_output}")
            
            # è§£æLLMè¿”å›çš„JSON
            parsed_result = self._parse_llm_response(llm_output)
            
            # æƒ…å†µ5: LLMè¾“å‡ºè§£æå¤±è´¥ ğŸ”§ éœ€Agent2å¤„ç†
            if not parsed_result:
                # ğŸ”§ ä¸ºAgent2æˆªæ–­æ£€ç´¢å†…å®¹ï¼Œé¿å…ä¼ é€’è¿‡é•¿å†…å®¹
                retrieval_content_for_agent2 = file_contents_str
                if len(retrieval_content_for_agent2) > 40000:
                    print(f"[PolicyHybridRetrievalTool] ä¼ é€’ç»™Agent2çš„å†…å®¹è¿‡é•¿({len(retrieval_content_for_agent2)}å­—ç¬¦)ï¼Œæˆªæ–­è‡³40000å­—ç¬¦")
                    retrieval_content_for_agent2 = retrieval_content_for_agent2[:40000] + "\n\n[å†…å®¹å› é•¿åº¦é™åˆ¶è¢«æˆªæ–­...]"
                
                return PolicyRetrievalResponse(
                    question=question,
                    answer="æ£€ç´¢åˆ°ç›¸å…³å†…å®¹ä½†LLMå¤„ç†å¤±è´¥",
                    reference_files=list(file_info_map.values()),
                    is_found=False,
                    error="LLMå¤„ç†å¤±è´¥",
                    failure_type="needs_agent2",  # éœ€è¦Agent2å¤„ç†
                    retrieval_content=retrieval_content_for_agent2,  # å…³é”®ï¼šè¿”å›æˆªæ–­åçš„æ£€ç´¢å†…å®¹
                    debug_info={"step": "llm_parsing_failed", "llm_raw_output": llm_output}
                )
            
            # æ ¹æ®LLMè¿”å›çš„å‚è€ƒæ–‡ä»¶åï¼Œè¡¥å……è¯¦ç»†ä¿¡æ¯
            reference_files = []
            for file_name in parsed_result.get("sources", []):
                if file_name in file_info_map:
                    reference_files.append(file_info_map[file_name])
                else:
                    print(f"[PolicyHybridRetrievalTool] è­¦å‘Š: LLMè¿”å›çš„æ–‡ä»¶å '{file_name}' æœªæ‰¾åˆ°å¯¹åº”ä¿¡æ¯")
            
            answer = parsed_result.get("answer", "")
            
            # æƒ…å†µ6: LLMè¿”å›"æ— æ³•æ‰¾åˆ°ç›¸å…³è§„å®š" âŒ æœ€ç»ˆå¤±è´¥
            if answer == "æ ¹æ®æ£€ç´¢çš„æ”¿ç­–æ–‡ä»¶æ— æ³•æ‰¾åˆ°ç›¸å…³è§„å®š":
                return PolicyRetrievalResponse(
                    question=question,
                    answer=answer,
                    reference_files=[],  # finalç±»å‹è¿”å›ç©ºåˆ—è¡¨
                    is_found=False,
                    error=None,  # è¿™ä¸æ˜¯é”™è¯¯ï¼Œæ˜¯æ­£å¸¸çš„"æœªæ‰¾åˆ°"
                    failure_type="final",  # æœ€ç»ˆå¤±è´¥
                    debug_info={"step": "llm_answered", "llm_conclusion": "no_relevant_policy"}
                )
            
            # æƒ…å†µ7: æˆåŠŸæ‰¾åˆ°ç­”æ¡ˆ âœ…
            return PolicyRetrievalResponse(
                question=question,
                answer=answer,
                reference_files=reference_files,
                is_found=True,
                error=None,
                failure_type=None,  # æˆåŠŸæ— å¤±è´¥ç±»å‹
                debug_info={"step": "completed", "files_count": len(file_groups)}
            )
            
        except Exception as e:
            print(f"[PolicyHybridRetrievalTool] ç»Ÿä¸€LLMé—®ç­”å¤±è´¥: {e}")
            
            # æƒ…å†µ4: LLMè°ƒç”¨å¼‚å¸¸ ğŸ”§ éœ€Agent2å¤„ç†
            all_files = [
                {
                    "document_title": group.document_title,
                    "publish_date": group.publish_date,
                    "issuing_agency": group.issuing_agency,
                    "website": group.website
                }
                for group in file_groups
            ]
            
            # å‡†å¤‡ç»™Agent2çš„æ£€ç´¢å†…å®¹
            file_contents_parts = []
            for group in file_groups:
                file_content = f"""
æ–‡ä»¶åï¼š{group.document_title}
å‘å¸ƒæ—¥æœŸï¼š{group.publish_date}
å‘å¸ƒæœºæ„ï¼š{group.issuing_agency}
ç½‘ç«™æ¥æºï¼š{group.website}

æ–‡ä»¶å†…å®¹ï¼š
{group.merged_text}
"""
                file_contents_parts.append(file_content)
            
            retrieval_content = "\n" + "="*50 + "\n".join(file_contents_parts)
            
            # ğŸ”§ ä¸ºAgent2æˆªæ–­æ£€ç´¢å†…å®¹ï¼Œé¿å…ä¼ é€’è¿‡é•¿å†…å®¹
            if len(retrieval_content) > 40000:
                print(f"[PolicyHybridRetrievalTool] ä¼ é€’ç»™Agent2çš„å†…å®¹è¿‡é•¿({len(retrieval_content)}å­—ç¬¦)ï¼Œæˆªæ–­è‡³40000å­—ç¬¦")
                retrieval_content = retrieval_content[:40000] + "\n\n[å†…å®¹å› é•¿åº¦é™åˆ¶è¢«æˆªæ–­...]"
            
            return PolicyRetrievalResponse(
                question=question,
                answer="æ£€ç´¢åˆ°ç›¸å…³å†…å®¹ä½†LLMå¤„ç†å¤±è´¥",
                reference_files=all_files,
                is_found=False,
                error="LLMå¤„ç†å¤±è´¥",
                failure_type="needs_agent2",  # éœ€è¦Agent2å¤„ç†
                retrieval_content=retrieval_content,  # å…³é”®ï¼šè¿”å›æˆªæ–­åçš„æ£€ç´¢å†…å®¹
                debug_info={"step": "llm_call_failed", "llm_error": str(e)}
            )
    
    def _parse_llm_response(self, llm_output: str) -> Optional[Dict]:
        """
        è§£æLLMçš„JSONå“åº”ï¼ŒåŒ…å«å¤šç§è§£æç­–ç•¥å’Œé”™è¯¯æ¢å¤æœºåˆ¶ - å¢å¼ºç‰ˆ
        """
        import re
        import json
        
        # å¤šçº§è§£æé€»è¾‘ - ä¸å…¶ä»–æ£€ç´¢å·¥å…·ä¿æŒä¸€è‡´ä¸”å¢å¼º
        def robust_json_parse(response_text):
            """Robust JSONè§£æï¼ŒåŒ…å«å¤šçº§fallbackæœºåˆ¶"""
            
            # ç­–ç•¥1: ç›´æ¥è§£æåŸå§‹è¾“å‡º
            try:
                return json.loads(response_text.strip())
            except json.JSONDecodeError as e:
                print(f"[PolicyHybridRetrievalTool] ç›´æ¥JSONè§£æå¤±è´¥: {e}")
                pass
            
            # ç­–ç•¥1.5: æ¸…ç†æ¢è¡Œç¬¦åè§£æï¼ˆç²¾ç¡®å¤„ç†JSONå­—ç¬¦ä¸²å€¼ï¼‰
            try:
                # æ›´ç²¾ç¡®çš„æ¢è¡Œç¬¦å¤„ç†æ–¹æ³•
                cleaned_text = response_text
                # æŸ¥æ‰¾JSONå¯¹è±¡çš„è¾¹ç•Œ
                start_idx = cleaned_text.find('{')
                end_idx = cleaned_text.rfind('}')
                if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
                    json_part = cleaned_text[start_idx:end_idx+1]
                    
                    # ç²¾ç¡®å¤„ç†JSONå­—ç¬¦ä¸²å€¼ä¸­çš„æ¢è¡Œç¬¦
                    def clean_json_value(match):
                        key = match.group(1)
                        value = match.group(2)
                        # è½¬ä¹‰æ¢è¡Œç¬¦å’Œå…¶ä»–æ§åˆ¶å­—ç¬¦ï¼Œä½†ä¿ç•™å·²è½¬ä¹‰çš„
                        value = value.replace('\n', '\\n').replace('\r', '\\r').replace('\t', '\\t')
                        return f'"{key}": "{value}"'
                    
                    # å¤„ç†JSONå­—ç¬¦ä¸²å€¼ - ä¿®æ­£æ­£åˆ™è¡¨è¾¾å¼ä»¥æ­£ç¡®åŒ¹é…åŒ…å«æ¢è¡Œç¬¦çš„å€¼
                    cleaned_json = re.sub(r'"([^"]+)"\s*:\s*"((?:[^"\\]|\\.)*)"', clean_json_value, json_part, flags=re.DOTALL)
                    # å°†æ¸…ç†åçš„JSONé‡æ–°ç»„åˆ
                    cleaned_text = cleaned_text[:start_idx] + cleaned_json + cleaned_text[end_idx+1:]
                
                return json.loads(cleaned_text.strip())
            except json.JSONDecodeError as e:
                print(f"[PolicyHybridRetrievalTool] æ¢è¡Œç¬¦æ¸…ç†åJSONè§£æå¤±è´¥: {e}")
                pass
            
            # ç­–ç•¥2: å»é™¤markdownåŒ…è£…
            try:
                # å¤„ç†```jsonåŒ…è£…
                if "```json" in response_text:
                    match = re.search(r'```json\s*(.*?)\s*```', response_text, re.DOTALL)
                    if match:
                        return json.loads(match.group(1).strip())
                
                # å¤„ç†æ™®é€š```åŒ…è£…
                if "```" in response_text:
                    match = re.search(r'```\s*(.*?)\s*```', response_text, re.DOTALL)
                    if match:
                        return json.loads(match.group(1).strip())
            except json.JSONDecodeError as e:
                print(f"[PolicyHybridRetrievalTool] Markdownæ¸…ç†åJSONè§£æå¤±è´¥: {e}")
                pass
            
            # ç­–ç•¥3: æ™ºèƒ½JSONå¯¹è±¡æå–ï¼ˆæ”¯æŒåµŒå¥—ç»“æ„ï¼‰
            try:
                # æ”¹è¿›çš„JSONå¯¹è±¡åŒ¹é… - å¤„ç†åµŒå¥—ç»“æ„
                if '"answer"' in response_text and '"sources"' in response_text:
                    # æ‰¾åˆ°ç¬¬ä¸€ä¸ª{çš„ä½ç½®
                    start_pos = response_text.find('{')
                    if start_pos != -1:
                        # ä»{å¼€å§‹ï¼ŒåŒ¹é…å¯¹åº”çš„}
                        brace_count = 0
                        for i, char in enumerate(response_text[start_pos:], start_pos):
                            if char == '{':
                                brace_count += 1
                            elif char == '}':
                                brace_count -= 1
                                if brace_count == 0:
                                    # æ‰¾åˆ°åŒ¹é…çš„}
                                    json_str = response_text[start_pos:i+1]
                                    return json.loads(json_str)
                
                # å¦‚æœä¸Šé¢æ–¹æ³•å¤±è´¥ï¼Œç”¨ç®€å•çš„æ­£åˆ™åŒ¹é…
                json_match = re.search(r'\{.*?\}', response_text, re.DOTALL)
                if json_match:
                    return json.loads(json_match.group(0))
            except json.JSONDecodeError as e:
                print(f"[PolicyHybridRetrievalTool] æ™ºèƒ½JSONæå–åè§£æå¤±è´¥: {e}")
                pass
            
            # ç­–ç•¥4: å¢å¼ºçš„æ­£åˆ™è¡¨è¾¾å¼é€æ­¥åŒ¹é…å…³é”®å­—æ®µ
            try:
                answer = ""
                sources = []
                
                # æå–answerå­—æ®µ - æ”¯æŒåŒ…å«å¼•å·å’Œæ¢è¡Œçš„å†…å®¹
                answer_patterns = [
                    r'"answer"\s*:\s*"((?:[^"\\]|\\.)*)"',  # å¤„ç†è½¬ä¹‰å¼•å·
                    r'"answer"\s*:\s*"([^"]*)"',           # ç®€å•æƒ…å†µ
                ]
                
                for pattern in answer_patterns:
                    answer_match = re.search(pattern, response_text, re.DOTALL)
                    if answer_match:
                        answer = answer_match.group(1)
                        # å¤„ç†è½¬ä¹‰å­—ç¬¦ï¼Œä½†ä¿ç•™æ¢è¡Œç»“æ„
                        answer = answer.replace('\\"', '"').replace('\\\\', '\\')
                        break
                
                # æå–sourceså­—æ®µ - æ›´robustçš„åŒ¹é…
                sources_patterns = [
                    r'"sources"\s*:\s*\[(.*?)\]',          # åŸºæœ¬åŒ¹é…
                    r'"sources"\s*:\s*\[([^\]]*)\]',       # æ›´ä¸¥æ ¼çš„åŒ¹é…
                ]
                
                for pattern in sources_patterns:
                    sources_match = re.search(pattern, response_text, re.DOTALL)
                    if sources_match:
                        sources_content = sources_match.group(1)
                        # æå–å¼•å·ä¸­çš„æ–‡ä»¶åï¼Œå¤„ç†å„ç§æ ¼å¼
                        file_patterns = [
                            r'"([^"]+)"',                  # æ ‡å‡†æ ¼å¼
                            r"'([^']+)'",                  # å•å¼•å·æ ¼å¼
                            r'([^,\[\]\s]+)',             # æ— å¼•å·æ ¼å¼
                        ]
                        
                        for file_pattern in file_patterns:
                            file_matches = re.findall(file_pattern, sources_content)
                            sources.extend(file_matches)
                        
                        # å»é‡å¹¶æ¸…ç†
                        sources = list(set([s.strip() for s in sources if s.strip()]))
                        break
                
                if answer:  # åªè¦æœ‰answerå°±è¿”å›
                    return {"answer": answer, "sources": sources}
                    
            except Exception as e:
                print(f"[PolicyHybridRetrievalTool] å¢å¼ºæ­£åˆ™è¡¨è¾¾å¼è§£æå¤±è´¥: {e}")
                pass
            
        
        try:
            # ä½¿ç”¨robustè§£æ
            result = robust_json_parse(llm_output)
            
            if result and result.get("answer"):
                print(f"[PolicyHybridRetrievalTool] JSONè§£ææˆåŠŸï¼Œansweré•¿åº¦: {len(result['answer'])}, sources: {result.get('sources', [])}")
                return result
            else:
                print(f"[PolicyHybridRetrievalTool] è§£æç»“æœç¼ºå°‘æœ‰æ•ˆç­”æ¡ˆ")
                return None
                
        except Exception as e:
            print(f"[PolicyHybridRetrievalTool] JSONè§£æå¼‚å¸¸: {e}")
            print(f"åŸå§‹è¾“å‡º: {llm_output[:500]}...")
            return None
    
    def _handle_exception_by_progress(self, question: str, exception: Exception, 
                                     search_results, scores, scored_results, file_groups) -> PolicyRetrievalResponse:
        """
        æ ¹æ®å·²å®Œæˆçš„æ­¥éª¤æ™ºèƒ½å¤„ç†å¼‚å¸¸ï¼Œç¡®ä¿æ­£ç¡®çš„å¤±è´¥ç±»å‹åˆ†ç±»
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            exception: å‘ç”Ÿçš„å¼‚å¸¸
            search_results: æ··åˆæ£€ç´¢ç»“æœ
            scores: ç›¸å…³æ€§æ‰“åˆ†ç»“æœ
            scored_results: è¿‡æ»¤åçš„é«˜åˆ†è¯­å—
            file_groups: æŒ‰æ–‡ä»¶åˆ†ç»„çš„ç»“æœ
            
        Returns:
            PolicyRetrievalResponse: æ ¹æ®è¿›åº¦åˆ†ç±»çš„å“åº”
        """
        error_msg = str(exception)
        print(f"[PolicyHybridRetrievalTool] æ™ºèƒ½å¼‚å¸¸å¤„ç† - å¼‚å¸¸: {error_msg}")
        
        # æƒ…å†µåˆ†æï¼šæ ¹æ®å·²å®Œæˆçš„æ­¥éª¤åˆ¤æ–­åº”è¯¥è¿”å›çš„å¤±è´¥ç±»å‹
        
        # å¦‚æœè¿æ£€ç´¢ç»“æœéƒ½æ²¡æœ‰ï¼Œè¯´æ˜æ˜¯æ—©æœŸé˜¶æ®µå¤±è´¥ -> retryable
        if search_results is None:
            print(f"[PolicyHybridRetrievalTool] å¼‚å¸¸å‘ç”Ÿåœ¨æ··åˆæ£€ç´¢é˜¶æ®µ")
            return PolicyRetrievalResponse(
                question=question,
                answer="æ”¿ç­–æ–‡ä»¶æ£€ç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯",
                reference_files=[],
                is_found=False,
                error=error_msg,
                failure_type="retryable",  # æ—©æœŸé˜¶æ®µå¤±è´¥ï¼Œå¯é‡è¯•
                debug_info={"step": "early_stage_error", "exception": error_msg}
            )
        
        # å¦‚æœæœ‰æ£€ç´¢ç»“æœä½†æ²¡æœ‰æ‰“åˆ†ç»“æœï¼Œè¯´æ˜æ˜¯ç›¸å…³æ€§æ‰“åˆ†é˜¶æ®µå¤±è´¥ -> retryable
        if scores is None:
            print(f"[PolicyHybridRetrievalTool] å¼‚å¸¸å‘ç”Ÿåœ¨ç›¸å…³æ€§æ‰“åˆ†é˜¶æ®µ")
            return PolicyRetrievalResponse(
                question=question,
                answer="æ”¿ç­–æ–‡ä»¶æ£€ç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯",
                reference_files=[],
                is_found=False,
                error=error_msg,
                failure_type="retryable",  # ç›¸å…³æ€§æ‰“åˆ†å¤±è´¥ï¼Œå¯é‡è¯•
                debug_info={"step": "scoring_error", "exception": error_msg, "search_results_count": len(search_results)}
            )
        
        # å…³é”®ï¼šå¦‚æœå·²ç»å®Œæˆæ‰“åˆ†ä¸”æ²¡æœ‰4åˆ†ä»¥ä¸Šè¯­å—ï¼Œè¯´æ˜æ˜¯æƒ…å†µ2 -> final
        if scored_results is not None and len(scored_results) == 0:
            print(f"[PolicyHybridRetrievalTool] å¼‚å¸¸å‘ç”Ÿä½†å·²ç¡®å®šæ— 4åˆ†ä»¥ä¸Šè¯­å— - åº”ä¸ºæœ€ç»ˆå¤±è´¥")
            return PolicyRetrievalResponse(
                question=question,
                answer="æ ¹æ®æ£€ç´¢çš„æ”¿ç­–æ–‡ä»¶æ— æ³•æ‰¾åˆ°ç›¸å…³è§„å®š",
                reference_files=[],
                is_found=False,
                error="æ²¡æœ‰æ‰¾åˆ°ç›¸å…³æ€§è¶³å¤Ÿé«˜çš„å†…å®¹",
                failure_type="final",  # ç¡®å®šæ— é«˜ç›¸å…³æ€§å†…å®¹ï¼Œæœ€ç»ˆå¤±è´¥
                debug_info={
                    "step": "no_high_relevance_confirmed", 
                    "max_score": max(scores) if scores else 0,
                    "total_results": len(search_results),
                    "original_exception": error_msg
                }
            )
        
        # å¦‚æœæœ‰é«˜åˆ†è¯­å—ï¼Œè¯´æ˜å¼‚å¸¸å‘ç”Ÿåœ¨LLMå¤„ç†é˜¶æ®µ -> needs_agent2
        if scored_results is not None and len(scored_results) > 0:
            print(f"[PolicyHybridRetrievalTool] å¼‚å¸¸å‘ç”Ÿåœ¨LLMå¤„ç†é˜¶æ®µï¼Œæœ‰{len(scored_results)}ä¸ªé«˜åˆ†è¯­å—")
            
            # å‡†å¤‡æ–‡ä»¶ä¿¡æ¯å’Œæ£€ç´¢å†…å®¹ç»™Agent2
            if file_groups is not None:
                # å¦‚æœå·²ç»æœ‰æ–‡ä»¶åˆ†ç»„
                all_files = [
                    {
                        "document_title": group.document_title,
                        "publish_date": group.publish_date,
                        "issuing_agency": group.issuing_agency,
                        "website": group.website
                    }
                    for group in file_groups
                ]
                
                file_contents_parts = []
                for group in file_groups:
                    file_content = f"""
æ–‡ä»¶åï¼š{group.document_title}
å‘å¸ƒæ—¥æœŸï¼š{group.publish_date}
å‘å¸ƒæœºæ„ï¼š{group.issuing_agency}
ç½‘ç«™æ¥æºï¼š{group.website}

æ–‡ä»¶å†…å®¹ï¼š
{group.merged_text}
"""
                    file_contents_parts.append(file_content)
                
                retrieval_content = "\n" + "="*50 + "\n".join(file_contents_parts)
            else:
                # å¦‚æœè¿˜æ²¡æœ‰åˆ†ç»„ï¼Œä»scored_resultsæ„å»º
                all_files = []
                file_contents_parts = []
                
                for scored_result in scored_results:
                    result = scored_result.search_result
                    file_info = {
                        "document_title": result.document_title,
                        "publish_date": result.publish_date,
                        "issuing_agency": result.issuing_agency,
                        "website": result.website
                    }
                    if file_info not in all_files:
                        all_files.append(file_info)
                    
                    file_content = f"""
æ–‡ä»¶åï¼š{result.document_title}
å†…å®¹ç‰‡æ®µï¼š
{scored_result.expanded_text_initial}
"""
                    file_contents_parts.append(file_content)
                
                retrieval_content = "\n".join(file_contents_parts)
            
            # ğŸ”§ ä¸ºAgent2æˆªæ–­æ£€ç´¢å†…å®¹ï¼Œé¿å…ä¼ é€’è¿‡é•¿å†…å®¹
            if len(retrieval_content) > 40000:
                print(f"[PolicyHybridRetrievalTool] ä¼ é€’ç»™Agent2çš„å†…å®¹è¿‡é•¿({len(retrieval_content)}å­—ç¬¦)ï¼Œæˆªæ–­è‡³40000å­—ç¬¦")
                retrieval_content = retrieval_content[:40000] + "\n\n[å†…å®¹å› é•¿åº¦é™åˆ¶è¢«æˆªæ–­...]"
            
            return PolicyRetrievalResponse(
                question=question,
                answer="æ£€ç´¢åˆ°ç›¸å…³å†…å®¹ä½†LLMå¤„ç†å¤±è´¥",
                reference_files=all_files,
                is_found=False,
                error="LLMå¤„ç†å¤±è´¥",
                failure_type="needs_agent2",  # éœ€è¦Agent2å¤„ç†
                retrieval_content=retrieval_content,
                debug_info={"step": "llm_stage_error", "llm_error": error_msg, "high_score_chunks": len(scored_results)}
            )
        
        # å…œåº•æƒ…å†µï¼šæœªçŸ¥é˜¶æ®µå¼‚å¸¸ -> retryable
        print(f"[PolicyHybridRetrievalTool] æœªçŸ¥é˜¶æ®µå¼‚å¸¸ï¼Œå…œåº•ä¸ºå¯é‡è¯•")
        return PolicyRetrievalResponse(
            question=question,
            answer="æ”¿ç­–æ–‡ä»¶æ£€ç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯",
            reference_files=[],
            is_found=False,
            error=error_msg,
            failure_type="retryable",  # æœªçŸ¥é”™è¯¯ï¼Œå¯é‡è¯•
            debug_info={"step": "unknown_stage_error", "exception": error_msg}
        )

    def close(self):
        """å…³é—­æ‰€æœ‰è¿æ¥"""
        self.hybrid_search_tool.close()
        self.text_processor.close()
        print("[PolicyHybridRetrievalTool] æ‰€æœ‰è¿æ¥å·²å…³é—­")

# ä¾¿æ·å‡½æ•°
def execute_policy_retrieval(question: str) -> PolicyRetrievalResponse:
    """æ‰§è¡Œæ”¿ç­–æ–‡ä»¶æ£€ç´¢çš„ä¾¿æ·å‡½æ•°"""
    tool = PolicyHybridRetrievalTool()
    try:
        return tool.execute_retrieval(question)
    finally:
        tool.close()
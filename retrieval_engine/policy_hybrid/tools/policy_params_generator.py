# tools/policy_params_generator.py
"""
æ”¿ç­–æ–‡ä»¶æ£€ç´¢å‚æ•°ç”Ÿæˆå™¨ - è°ƒç”¨å¤§æ¨¡å‹ç”ŸæˆVECTOR_QUESTIONå’ŒKEYWORDS
"""
import sys
import os
import json

# æ·»åŠ è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(current_dir)))))
sys.path.insert(0, project_root)

from knowledge_retrieval.config.prompts import POLICY_SEARCH_PARAMS_GENERATION_PROMPT

class PolicySearchParams:
    """æ”¿ç­–æ–‡ä»¶æ£€ç´¢å‚æ•°"""
    def __init__(self, vector_question: str, keywords: list):
        self.vector_question = vector_question
        self.keywords = keywords

class PolicySearchParamsGenerator:
    """æ”¿ç­–æ–‡ä»¶æ£€ç´¢å‚æ•°ç”Ÿæˆå™¨ - ä½¿ç”¨LLMç”Ÿæˆä¼˜åŒ–çš„VECTOR_QUESTIONå’ŒKEYWORDS"""
    
    def __init__(self):
        print("[PolicySearchParamsGenerator] åˆå§‹åŒ–å®Œæˆ")
        self._setup_llm()
    
    def _setup_llm(self):
        """è®¾ç½®LLMå®¢æˆ·ç«¯"""
        try:
            from knowledge_retrieval.config.model_config import MODEL_CONFIG
            from openai import OpenAI
            
            # ä½¿ç”¨é…ç½®ä¸­çš„LLMè®¾ç½®
            llm_config = MODEL_CONFIG["ali"]["deepseek-v3"]  # æˆ–è€…ä½¿ç”¨æ‚¨é…ç½®çš„å…¶ä»–æ¨¡å‹
            self.llm_client = OpenAI(
                api_key=llm_config["api_key"],
                base_url=llm_config["base_url"]
            )
            self.model_name = llm_config["model"]
            print(f"[PolicySearchParamsGenerator] LLMå®¢æˆ·ç«¯è®¾ç½®å®Œæˆï¼Œä½¿ç”¨æ¨¡å‹: {self.model_name}")
            
        except Exception as e:
            print(f"[PolicySearchParamsGenerator] LLMè®¾ç½®å¤±è´¥: {e}")
            self.llm_client = None
            self.model_name = None
    
    def generate_search_params(self, question: str, verbose: bool = False) -> PolicySearchParams:
        """
        ä½¿ç”¨å¤§æ¨¡å‹ç”Ÿæˆæ”¿ç­–æ–‡ä»¶æ··åˆæ£€ç´¢å‚æ•°
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
            
        Returns:
            PolicySearchParams: åŒ…å«vector_questionå’Œkeywordsçš„å‚æ•°
        """
        print(f"[PolicySearchParamsGenerator] å¼€å§‹è°ƒç”¨LLMç”Ÿæˆæ£€ç´¢å‚æ•°: {question}")
        
        if not self.llm_client:
            print("[PolicySearchParamsGenerator] LLMæœªè®¾ç½®ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")
            return self._fallback_generate_params(question)
        
        try:
            # æ„å»ºé’ˆå¯¹æ”¿ç­–æ–‡ä»¶çš„æç¤ºè¯
            prompt = POLICY_SEARCH_PARAMS_GENERATION_PROMPT.format(question=question)
            
            if verbose:
                print(f"[PolicySearchParamsGenerator] ğŸ“ å®Œæ•´æç¤ºè¯å†…å®¹:")
                print("=" * 80)
                print(prompt)
                print("=" * 80)
                print(f"[PolicySearchParamsGenerator] ğŸ“¥ LLMè°ƒç”¨å‚æ•°:")
                print(f"  - æ¨¡å‹: {self.model_name}")
                print(f"  - æ¸©åº¦: 0.0")
                print(f"  - æç¤ºè¯é•¿åº¦: {len(prompt)} å­—ç¬¦")
            
            # è°ƒç”¨LLM
            response = self.llm_client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "user", "content": prompt}
                ],
                temperature=0.0  # ä½¿ç”¨ç¡®å®šæ€§è¾“å‡º
            )
            
            llm_output = response.choices[0].message.content.strip()
            
            if verbose:
                print(f"[PolicySearchParamsGenerator] ğŸ“¤ LLMå“åº”ä¿¡æ¯:")
                print(f"  - è¾“å‡ºé•¿åº¦: {len(llm_output)} å­—ç¬¦")
                print(f"  - ä½¿ç”¨tokenæ•°: {response.usage.total_tokens if hasattr(response, 'usage') else 'æœªçŸ¥'}")
                print(f"[PolicySearchParamsGenerator] ğŸ” LLMå®Œæ•´åŸå§‹è¾“å‡º:")
                print("-" * 80)
                print(llm_output)
                print("-" * 80)
            else:
                print(f"[PolicySearchParamsGenerator] LLMåŸå§‹è¾“å‡º: {llm_output}")
            
            # è§£æJSONè¾“å‡º
            params_data = self._parse_llm_output(llm_output)
            
            result = PolicySearchParams(
                vector_question=params_data.get("vector_question", question),
                keywords=params_data.get("keywords", self._extract_fallback_keywords(question))
            )
            
            print(f"[PolicySearchParamsGenerator] ç”Ÿæˆç»“æœ:")
            print(f"  å‘é‡é—®é¢˜: {result.vector_question}")
            print(f"  å…³é”®è¯: {result.keywords}")
            
            return result
            
        except Exception as e:
            print(f"[PolicySearchParamsGenerator] LLMè°ƒç”¨å¤±è´¥: {e}")
            return self._fallback_generate_params(question)
    
    
    def _parse_llm_output(self, llm_output: str) -> dict:
        """è§£æLLMçš„JSONè¾“å‡º"""
        try:
            # å°è¯•ç›´æ¥è§£æJSON
            return json.loads(llm_output)
        except json.JSONDecodeError as e:
            print(f"[PolicySearchParamsGenerator] ç›´æ¥JSONè§£æå¤±è´¥: {e}")
            # å¦‚æœç›´æ¥è§£æå¤±è´¥ï¼Œå°è¯•æå–JSONéƒ¨åˆ†
            import re
            
            # å°è¯•æŸ¥æ‰¾å®Œæ•´çš„JSONå¯¹è±¡
            json_pattern = r'\{[^{}]*"vector_question"[^{}]*"keywords"[^{}]*\}'
            matches = re.findall(json_pattern, llm_output, re.DOTALL | re.MULTILINE)
            
            for match in matches:
                try:
                    print(f"[PolicySearchParamsGenerator] å°è¯•è§£æJSONç‰‡æ®µ: {match}")
                    return json.loads(match)
                except json.JSONDecodeError:
                    continue
            
            # å¦‚æœæ²¡æ‰¾åˆ°å®Œæ•´JSONï¼Œå°è¯•é€å­—æ®µæå–
            print("[PolicySearchParamsGenerator] å°è¯•é€å­—æ®µæå–...")
            if '"vector_question"' in llm_output and '"keywords"' in llm_output:
                try:
                    # æå–å¼•å·å†…çš„å†…å®¹
                    vector_q_match = re.search(r'"vector_question"\s*:\s*"([^"]*)"', llm_output)
                    keywords_match = re.search(r'"keywords"\s*:\s*\[([^\]]*)\]', llm_output)
                    
                    if vector_q_match:
                        vector_question = vector_q_match.group(1)
                        keywords = []
                        
                        if keywords_match:
                            keywords_text = keywords_match.group(1)
                            # æå–å…³é”®è¯
                            keyword_matches = re.findall(r'"([^"]*)"', keywords_text)
                            keywords = keyword_matches
                        
                        result = {
                            "vector_question": vector_question,
                            "keywords": keywords
                        }
                        print(f"[PolicySearchParamsGenerator] å­—æ®µæå–æˆåŠŸ: {result}")
                        return result
                except Exception as e:
                    print(f"[PolicySearchParamsGenerator] å­—æ®µæå–å¤±è´¥: {e}")
            
            # å¦‚æœéƒ½å¤±è´¥äº†ï¼Œè¿”å›ç©ºå­—å…¸
            print(f"[PolicySearchParamsGenerator] å®Œå…¨è§£æå¤±è´¥ï¼ŒLLMåŸå§‹è¾“å‡º:")
            print(f"  è¾“å‡ºé•¿åº¦: {len(llm_output)}")
            print(f"  è¾“å‡ºå†…å®¹: {repr(llm_output)}")
            return {}
    
    def _fallback_generate_params(self, question: str) -> PolicySearchParams:
        """å¤‡ç”¨å‚æ•°ç”Ÿæˆæ–¹æ¡ˆï¼ˆå½“LLMä¸å¯ç”¨æ—¶ï¼‰"""
        print("[PolicySearchParamsGenerator] ä½¿ç”¨å¤‡ç”¨å‚æ•°ç”Ÿæˆæ–¹æ¡ˆ")
        
        return PolicySearchParams(
            vector_question=question.strip(),  # ç›´æ¥ä½¿ç”¨åŸé—®é¢˜
            keywords=self._extract_fallback_keywords(question)
        )
    
    def _extract_fallback_keywords(self, question: str) -> list:
        """å¤‡ç”¨å…³é”®è¯æå– - é’ˆå¯¹æ”¿ç­–æ–‡ä»¶"""
        import re
        
        # ç§»é™¤å¸¸è§åœç”¨è¯
        stop_words = {
            'çš„', 'æ˜¯', 'åœ¨', 'æœ‰', 'å’Œ', 'ä¸', 'å¯¹', 'ä¸º', 'äº†', 'ç­‰', 'ä¸­', 'åŠ', 
            'ä»€ä¹ˆ', 'å¦‚ä½•', 'æ€æ ·', 'è¯·é—®', 'è¿™ä¸ª', 'é‚£ä¸ª', 'æ”¿ç­–', 'è§„å®š', 'æ–‡ä»¶'
        }
        
        # æå–ä¸­æ–‡è¯æ±‡ï¼ˆä¼˜å…ˆæ”¿ç­–ç›¸å…³æœ¯è¯­ï¼‰
        words = re.findall(r'[\u4e00-\u9fff]+', question)
        keywords = [w for w in words if len(w) >= 2 and w not in stop_words]
        
        # æå–æ•°å­—å’Œç™¾åˆ†æ¯”
        numbers = re.findall(r'\d+\.?\d*%?', question)
        keywords.extend(numbers)
        
        # æå–è‹±æ–‡å•è¯ï¼ˆå¦‚REITsç­‰ï¼‰
        english_words = re.findall(r'[A-Za-z]+', question)
        keywords.extend([w for w in english_words if len(w) >= 3])
        
        # å»é‡å¹¶é™åˆ¶æ•°é‡
        keywords = list(dict.fromkeys(keywords))[:5]  # æœ€å¤š5ä¸ªå…³é”®è¯
        
        return keywords

# ä¾¿æ·å‡½æ•°
def generate_policy_search_params(question: str, verbose: bool = False) -> PolicySearchParams:
    """ç”Ÿæˆæ”¿ç­–æ–‡ä»¶æ£€ç´¢å‚æ•°"""
    generator = PolicySearchParamsGenerator()
    return generator.generate_search_params(question, verbose=verbose)
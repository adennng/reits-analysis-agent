# config/model_config.py
# LLMæ¨¡å‹é…ç½®

import os

MODEL_CONFIG = {
    "zhipu": {
        "embedding-3": {
            "model": "embedding-3",
            "api_key": os.getenv("ZHIPU_API_KEY", "**"),
            "base_url": os.getenv("ZHIPU_BASE_URL", "https://open.bigmodel.cn/api/paas/v4/")
        },
        "glm-4.5": {
            "model": "glm-4.5",
            "api_key": os.getenv("ZHIPU_API_KEY", "**"),
            "base_url": os.getenv("ZHIPU_BASE_URL", "https://open.bigmodel.cn/api/paas/v4/")
        },
    },
    "ali": {
        "deepseek-v3": {
            "model": "deepseek-v3",
            "api_key": os.getenv("ALI_API_KEY", "**"),
            "base_url": os.getenv("ALI_BASE_URL", "https://dashscope.aliyuncs.com/compatible-mode/v1")
        },
        "qwen-long": {
            "model": "qwen-long",
            "api_key": os.getenv("ALI_API_KEY", "**"),
            "base_url": os.getenv("ALI_BASE_URL", "https://dashscope.aliyuncs.com/compatible-mode/v1")
        },
         "deepseek-r1": {
                  "model": "deepseek-r1",
                  "api_key": os.getenv("ALI_API_KEY", "**"),
                  "base_url": os.getenv("ALI_BASE_URL", "https://dashscope.aliyuncs.com/compatible-mode/v1")
         },
    },
    "deepseek": {
        "deepseek-chat": {
            "model": "deepseek-chat",
            "api_key": os.getenv("DEEPSEEK_API_KEY", "**"),
            "base_url": os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com")
        },
        "deepseek-reasoner": {
            "model": "deepseek-reasoner",
            "api_key": os.getenv("DEEPSEEK_API_KEY", "**"),
            "base_url": os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com")
        },
    }
}

# æ¨¡å‹åˆ›å»ºåŠŸèƒ½
def create_model(provider: str = "ali", model_name: str = "deepseek-v3"):
    """
    æ ¹æ®é…ç½®åˆ›å»ºæ¨¡å‹å®ä¾‹
    
    Args:
        provider: æä¾›å•†åç§°ï¼Œé»˜è®¤ "ali"
        model_name: æ¨¡å‹åç§°ï¼Œé»˜è®¤ "deepseek-v3"
        
    Returns:
        OpenAIChatCompletionsModel æˆ– None
    """
    try:
        from openai import AsyncOpenAI
        from agents.models.openai_chatcompletions import OpenAIChatCompletionsModel
        
        # è·å–é…ç½®
        config = MODEL_CONFIG.get(provider, {}).get(model_name)
        if not config:
            print(f"âŒ æœªæ‰¾åˆ° {provider}/{model_name} é…ç½®")
            return None
        
        print(f"ğŸ¤– ä½¿ç”¨ {provider}/{model_name} æ¨¡å‹")
        
        # åˆ›å»ºå®¢æˆ·ç«¯å’Œæ¨¡å‹
        openai_client = AsyncOpenAI(
            api_key=config['api_key'],
            base_url=config['base_url']
        )
        
        return OpenAIChatCompletionsModel(
            model=config['model'],
            openai_client=openai_client
        )
        
    except ImportError as e:
        print(f"âš ï¸ OpenAI Agentsæ¡†æ¶ä¸å¯ç”¨: {e}")
        return None
    except Exception as e:
        print(f"âŒ åˆ›å»ºæ¨¡å‹å¤±è´¥: {e}")
        return None

def get_deepseek_v3_model():
    """å¿«æ·æ–¹å¼ï¼šè·å–deepseek-v3æ¨¡å‹"""
    return create_model("ali", "deepseek-v3")

def get_deepseek_r1_model():
    """å¿«æ·æ–¹å¼ï¼šè·å–deepseek-r1æ¨¡å‹"""
    return create_model("ali", "deepseek-r1")
  
def get_deepseek_reasoner_model():
    """å¿«æ·æ–¹å¼ï¼šè·å–deepseek-reasoneræ¨¡å‹"""
    return create_model("deepseek", "deepseek-reasoner")    

def get_deepseek_chat_model():
    """å¿«æ·æ–¹å¼ï¼šè·å–deepseek-reasoneræ¨¡å‹"""
    return create_model("deepseek", "deepseek-chat")   

def get_glm_4_5_model():
    """å¿«æ·æ–¹å¼ï¼šè·å–glm-4.5æ¨¡å‹"""
    return create_model("zhipu", "glm-4.5")   

